{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3cwAxm0NRz",
        "outputId": "4e6ea27c-cfe9-4ad5-bc73-4423fdcc2b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM"
      ],
      "metadata": {
        "id": "U43uwoWA0zOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_retriever(corpus, model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    # Encode the corpus using the pre-trained model\n",
        "    corpus_embeddings = []\n",
        "    for doc in corpus:\n",
        "        inputs = tokenizer(doc, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            # Access the last hidden state from the outputs\n",
        "            embeddings = outputs[0].mean(dim=1).squeeze().numpy()  # outputs[0] gives you last_hidden_state\n",
        "\n",
        "            # Check if embeddings are valid before appending\n",
        "            if embeddings.ndim == 1:\n",
        "                corpus_embeddings.append(embeddings)\n",
        "\n",
        "    # Convert list to NumPy array\n",
        "    corpus_embeddings = np.array(corpus_embeddings)\n",
        "\n",
        "    # Check the shape of corpus_embeddings before proceeding\n",
        "    if corpus_embeddings.shape[0] == 0:\n",
        "        raise ValueError(\"No embeddings were generated. Check the input corpus.\")\n",
        "\n",
        "    # Build the Faiss index\n",
        "    index = faiss.IndexFlatIP(corpus_embeddings.shape[1])  # Use the correct dimension\n",
        "    index = faiss.IndexIDMap(index)\n",
        "    index.add_with_ids(corpus_embeddings, np.arange(len(corpus_embeddings)))\n",
        "\n",
        "    return index, tokenizer, model\n",
        "\n",
        "\n",
        "\n",
        "def retrieve_documents(query, index, tokenizer, model, k=5):\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        query_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "    # Search the Faiss index for the top-k relevant documents\n",
        "    scores, doc_ids = index.search(np.array([query_embedding]), k)\n",
        "    return [corpus[doc_id] for doc_id in doc_ids[0]]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ndiDKGe105Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the generative language model\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "def setup_generator(model_name):\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-base\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-base\")\n",
        "    return tokenizer, model\n",
        "\n",
        "def generate_response(query, documents, tokenizer, model):\n",
        "    if isinstance(documents, list) and documents:  # Check if documents is a non-empty list\n",
        "        documents = \" \".join(documents)  # Join list into a single string\n",
        "    elif not documents:  # If documents is empty\n",
        "        return \"No relevant documents found.\"\n",
        "    input_text = f\"question: {query} context: {' '.join(documents)}\"\n",
        "    inputs = tokenizer(query, documents, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "corpus = [\n",
        "    \"Since it was built and opened to the public in 1889, the Eiffel Tower instantly gained an international fame, as it was then the tallest building in the world. Its peculiar iron silhouette instantly traveled across the world in the newspapers.\",\n",
        "    \"The Louvre is the world's largest art museum and a historic monument in Paris, France.\",\n",
        "    \"The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor.\",\n",
        "]\n",
        "\n",
        "# Set up the retriever\n",
        "index, tokenizer, model = setup_retriever(corpus, \"bert-base-uncased\")\n",
        "\n",
        "# Set up the generator\n",
        "gen_tokenizer, gen_model = setup_generator(\"t5-base\")\n",
        "\n",
        "# Example query\n",
        "query = \"Tell me about Eiffel Tower\"\n",
        "\n",
        "# Retrieve relevant documents\n",
        "documents = retrieve_documents(query, index, tokenizer, model)\n",
        "print(\"Retrieved Documents:\", documents)\n",
        "\n",
        "# Generate the response\n",
        "if documents:\n",
        "    response = generate_response(query, documents, gen_tokenizer, gen_model,)\n",
        "    print(response)\n",
        "else:\n",
        "    print(\"No relevant documents found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOJQnSl4287z",
        "outputId": "5ff36c85-bce3-4945-ce0b-d270fe6ecc1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Output Tokens: BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1954,  0.0347, -0.2327,  ..., -0.2592,  0.2305,  0.4515],\n",
            "         [ 0.6018, -0.2306, -0.2690,  ...,  0.2318,  0.6845,  0.0312],\n",
            "         [-0.3186, -1.0884,  0.0023,  ...,  0.2784, -0.2035,  0.3597],\n",
            "         ...,\n",
            "         [ 0.6715,  0.2540, -0.1234,  ..., -0.5904, -0.3914,  0.0875],\n",
            "         [ 0.2941, -0.4231, -1.0190,  ...,  0.6464,  0.1077,  0.0045],\n",
            "         [ 1.0575,  0.0672, -0.3260,  ...,  0.1318, -0.6374, -0.1919]]]), pooler_output=tensor([[-8.8834e-01, -3.0073e-01, -1.1459e-02,  6.4608e-01, -1.5759e-02,\n",
            "          2.1981e-03,  7.9231e-01,  2.6701e-01,  7.7451e-02, -9.9995e-01,\n",
            "         -1.7979e-01,  4.8561e-01,  9.8979e-01, -1.1819e-01,  9.5052e-01,\n",
            "         -5.4916e-01,  1.2901e-01, -5.9009e-01,  2.3211e-01, -3.5158e-01,\n",
            "          6.3564e-01,  9.9492e-01,  4.6591e-01,  3.2373e-01,  4.0483e-01,\n",
            "          8.2039e-01, -6.1613e-01,  9.5330e-01,  9.5860e-01,  7.4825e-01,\n",
            "         -6.2977e-01,  1.5987e-01, -9.9283e-01, -9.6513e-02, -8.3120e-02,\n",
            "         -9.9312e-01,  3.3596e-01, -7.0669e-01,  1.6407e-01,  1.6789e-01,\n",
            "         -9.2499e-01,  2.3064e-01,  9.9976e-01, -3.5715e-01,  1.5146e-01,\n",
            "         -1.8868e-01, -9.9999e-01,  6.7453e-02, -9.0010e-01,  1.6307e-01,\n",
            "          7.3333e-02, -4.0241e-02,  7.5737e-02,  3.3224e-01,  3.8166e-01,\n",
            "          2.7384e-01, -2.4971e-01, -4.8246e-03, -2.3706e-01, -4.5701e-01,\n",
            "         -5.5716e-01,  1.8779e-01, -3.1509e-01, -8.9816e-01,  4.5201e-02,\n",
            "         -3.6645e-01, -5.7529e-02, -2.9435e-01,  6.7915e-03, -1.9414e-01,\n",
            "          7.9207e-01,  1.8474e-01,  1.8399e-01, -8.7507e-01, -2.7573e-01,\n",
            "          1.7078e-01, -6.2966e-01,  1.0000e+00, -2.4995e-01, -9.8796e-01,\n",
            "         -2.5038e-02, -9.6317e-02,  5.5559e-01,  5.2265e-01, -3.7966e-01,\n",
            "         -1.0000e+00,  3.3491e-01, -7.6505e-03, -9.9337e-01,  1.8783e-01,\n",
            "          3.0875e-01, -1.3077e-01, -5.1056e-01,  5.8483e-01, -8.5142e-02,\n",
            "         -3.2018e-01, -1.3596e-01, -2.8527e-01, -1.2456e-02,  8.8576e-03,\n",
            "         -6.9540e-03, -1.2616e-01, -7.6872e-02, -2.7259e-01,  1.8470e-01,\n",
            "         -4.4810e-01, -3.6718e-01,  1.6274e-01, -3.4572e-01,  5.6395e-01,\n",
            "          4.0014e-01, -2.8340e-01,  2.8738e-01, -9.6248e-01,  5.7363e-01,\n",
            "         -2.9932e-01, -9.9035e-01, -5.7529e-01, -9.9367e-01,  6.4820e-01,\n",
            "          1.0326e-01, -1.1542e-01,  9.6794e-01,  5.1502e-01,  3.3276e-01,\n",
            "          2.7765e-02, -7.7206e-03, -1.0000e+00, -3.5670e-01, -3.0090e-01,\n",
            "          2.8512e-01, -2.7891e-01, -9.8272e-01, -9.7401e-01,  5.4419e-01,\n",
            "          9.6218e-01,  7.6269e-02,  9.9955e-01, -2.5570e-01,  9.5932e-01,\n",
            "          3.6315e-01, -9.9588e-02, -2.6683e-01, -3.7305e-01,  4.5304e-01,\n",
            "          1.2320e-01, -5.1927e-01,  1.7908e-01,  9.7843e-02,  2.1028e-02,\n",
            "         -2.4622e-01, -2.1938e-01,  4.0832e-02, -9.6073e-01, -2.4602e-01,\n",
            "          9.6016e-01,  7.8765e-02, -1.0153e-02,  7.0878e-01, -2.4120e-01,\n",
            "         -2.6758e-01,  8.5170e-01,  2.5899e-01,  3.0733e-01, -1.3654e-01,\n",
            "          3.5045e-01, -4.3572e-01,  5.4698e-01, -8.0896e-01,  3.8030e-01,\n",
            "          3.8978e-01, -2.2531e-01, -2.0835e-02, -9.8836e-01, -3.0901e-01,\n",
            "          3.9101e-01,  9.9170e-01,  7.3482e-01,  2.6831e-01,  1.0147e-01,\n",
            "         -1.7077e-01,  5.0786e-01, -9.6514e-01,  9.8752e-01, -1.0403e-01,\n",
            "          2.8291e-01,  2.3363e-01, -9.1838e-06, -8.8415e-01, -3.8621e-01,\n",
            "          6.7551e-01, -2.8207e-01, -8.7000e-01,  1.2441e-01, -4.9262e-01,\n",
            "         -2.8669e-01, -1.7336e-01,  3.7077e-01, -2.2046e-01, -3.6170e-01,\n",
            "          4.9633e-02,  9.4125e-01,  9.4037e-01,  7.3454e-01, -5.7087e-01,\n",
            "          5.1733e-01, -9.0601e-01, -5.2069e-01,  4.1273e-02,  2.2342e-01,\n",
            "         -2.6275e-03,  9.9572e-01, -1.6810e-01, -8.0720e-02, -9.2700e-01,\n",
            "         -9.8940e-01, -7.3004e-02, -9.1441e-01,  2.4925e-03, -5.3481e-01,\n",
            "          4.3345e-01,  4.2394e-01, -2.2819e-01,  3.9837e-01, -9.6355e-01,\n",
            "         -7.6467e-01,  2.2534e-01, -3.6660e-01,  3.6321e-01, -2.3662e-01,\n",
            "          6.9558e-01,  4.3271e-01, -4.2400e-01,  3.9360e-01,  9.2713e-01,\n",
            "          6.8390e-02, -8.0159e-01,  7.4063e-01, -1.8363e-01,  8.1375e-01,\n",
            "         -5.0342e-01,  9.8320e-01,  3.0768e-01,  4.3433e-01, -9.5125e-01,\n",
            "          7.7617e-02, -7.7841e-01,  2.5709e-01, -4.2822e-02, -6.6154e-01,\n",
            "          1.4091e-01,  6.0148e-01,  3.6570e-01,  8.1693e-01, -4.6886e-01,\n",
            "          9.8534e-01, -6.8443e-01, -9.7072e-01, -3.2479e-01,  2.3879e-02,\n",
            "         -9.9153e-01,  2.8419e-01,  2.7638e-01, -4.4615e-01, -2.9759e-01,\n",
            "         -4.6442e-01, -9.7082e-01,  7.6789e-01,  3.6130e-02,  9.7226e-01,\n",
            "          1.2766e-02, -8.3617e-01, -3.0033e-01, -9.4717e-01, -1.5041e-01,\n",
            "         -7.9322e-02,  4.4441e-01, -2.7300e-01, -9.6558e-01,  4.5469e-01,\n",
            "          5.8144e-01,  4.8434e-01,  1.5751e-01,  9.9572e-01,  9.9995e-01,\n",
            "          9.7921e-01,  8.9934e-01,  8.4019e-01, -9.8295e-01, -3.2686e-01,\n",
            "          9.9998e-01, -8.1238e-01, -1.0000e+00, -9.4328e-01, -4.0210e-01,\n",
            "          3.2017e-01, -1.0000e+00, -1.7423e-01,  1.2495e-01, -9.2881e-01,\n",
            "         -1.4744e-01,  9.8608e-01,  9.7949e-01, -1.0000e+00,  8.5819e-01,\n",
            "          9.5623e-01, -6.3656e-01,  5.5625e-01, -1.8235e-01,  9.8341e-01,\n",
            "          2.6160e-01,  3.3560e-01, -5.3192e-02,  3.4807e-01, -1.7096e-01,\n",
            "         -8.1040e-01,  2.2930e-01,  3.7573e-02,  8.3834e-01,  2.0366e-02,\n",
            "         -6.7118e-01, -9.3437e-01,  1.7931e-01, -1.2808e-01, -4.2314e-01,\n",
            "         -9.7378e-01, -1.1703e-01, -3.3457e-02,  6.3830e-01, -1.3777e-03,\n",
            "          2.2630e-01, -6.4420e-01,  2.0223e-01, -5.9500e-01,  2.3839e-01,\n",
            "          7.2608e-01, -9.4804e-01, -4.9555e-01, -1.3937e-01, -4.5365e-01,\n",
            "          2.4740e-01, -9.7141e-01,  9.7207e-01, -2.8860e-01,  2.3664e-01,\n",
            "          1.0000e+00,  1.3935e-01, -8.9081e-01,  3.3814e-01,  1.0054e-01,\n",
            "         -3.0713e-01,  1.0000e+00,  4.8821e-01, -9.8482e-01, -5.4477e-01,\n",
            "          3.3697e-01, -3.5906e-01, -4.8359e-01,  9.9914e-01, -2.5703e-01,\n",
            "          3.0173e-01,  2.8694e-01,  9.8637e-01, -9.9306e-01,  8.5744e-01,\n",
            "         -8.9729e-01, -9.7880e-01,  9.7873e-01,  9.5785e-01, -2.4342e-01,\n",
            "         -7.0139e-01, -4.1475e-02,  1.2681e-01,  1.8981e-01, -9.3567e-01,\n",
            "          5.0401e-01,  4.1423e-01, -3.0629e-02,  9.1418e-01, -6.5936e-01,\n",
            "         -5.6187e-01,  3.2515e-01, -1.1179e-01,  3.5131e-01,  4.1589e-01,\n",
            "          3.8458e-01, -1.2961e-01, -7.6014e-02, -2.0198e-01, -4.8185e-01,\n",
            "         -9.7641e-01,  1.0385e-01,  1.0000e+00,  3.9310e-02, -7.2727e-02,\n",
            "         -5.4221e-03,  5.7604e-02, -3.1841e-01,  4.5284e-01,  4.2767e-01,\n",
            "         -2.5705e-01, -7.7788e-01,  2.5409e-01, -8.8310e-01, -9.9195e-01,\n",
            "          6.7138e-01,  7.6154e-02, -2.4688e-01,  9.9970e-01,  2.8419e-01,\n",
            "          7.9463e-02, -5.4378e-02,  6.6091e-01, -8.9864e-02,  3.6770e-01,\n",
            "         -1.5168e-01,  9.8435e-01, -1.9802e-01,  6.0578e-01,  7.4426e-01,\n",
            "         -1.2975e-01, -2.9286e-01, -5.5421e-01, -3.9404e-02, -9.4618e-01,\n",
            "          1.5119e-01, -9.6270e-01,  9.7413e-01,  1.5905e-01,  3.2427e-01,\n",
            "          6.8691e-02,  1.0098e-01,  1.0000e+00, -5.5177e-01,  5.2359e-01,\n",
            "          1.9263e-01,  6.8596e-01, -9.6944e-01, -7.9716e-01, -3.0597e-01,\n",
            "          1.4020e-01,  5.7420e-02, -2.5430e-01,  1.5934e-01, -9.7270e-01,\n",
            "         -1.2300e-01, -1.9899e-02, -9.6842e-01, -9.9475e-01,  5.1978e-01,\n",
            "          4.6816e-01,  1.0822e-01, -7.4184e-01, -6.0048e-01, -6.0706e-01,\n",
            "          1.4549e-01, -1.3478e-01, -9.5776e-01,  5.1825e-01, -1.7900e-01,\n",
            "          4.1073e-01, -1.6471e-01,  5.8030e-01, -7.0414e-02,  9.0638e-01,\n",
            "          1.9193e-01,  5.7785e-02, -3.6902e-02, -7.5139e-01,  7.1186e-01,\n",
            "         -7.5450e-01, -2.0278e-01, -1.2291e-01,  1.0000e+00, -3.1147e-01,\n",
            "          8.3311e-02,  7.2873e-01,  6.5088e-01, -1.9556e-01,  2.5517e-01,\n",
            "          2.6971e-01,  1.8300e-01,  2.8770e-01,  1.1254e-01, -6.5739e-02,\n",
            "         -3.0278e-01,  4.7324e-01, -2.7784e-01, -2.7682e-01,  8.1443e-01,\n",
            "          3.6737e-01,  1.0638e-02,  9.0988e-02, -7.6905e-02,  9.9702e-01,\n",
            "         -8.3250e-02,  1.3894e-01, -2.9461e-01, -8.3851e-02, -2.5942e-01,\n",
            "          3.8818e-02,  1.0000e+00,  2.0977e-01,  4.8512e-02, -9.9396e-01,\n",
            "         -2.0672e-01, -8.9332e-01,  9.9978e-01,  8.2605e-01, -7.5330e-01,\n",
            "          5.0105e-01,  3.1931e-01, -5.7919e-02,  5.8813e-01, -1.3550e-01,\n",
            "         -1.5381e-01,  8.6716e-02,  6.2208e-02,  9.6969e-01, -3.7497e-01,\n",
            "         -9.8092e-01, -5.7456e-01,  3.2040e-01, -9.7115e-01,  9.8628e-01,\n",
            "         -4.3778e-01, -1.8532e-01, -2.5154e-01,  7.6523e-02, -1.7503e-01,\n",
            "         -8.5010e-02, -9.8557e-01, -1.6374e-01,  5.5488e-02,  9.7188e-01,\n",
            "          2.2259e-01, -5.9125e-01, -9.3124e-01, -3.0390e-01,  2.2738e-01,\n",
            "         -1.3968e-01, -9.4678e-01,  9.7645e-01, -9.8505e-01,  4.3816e-01,\n",
            "          1.0000e+00,  1.5812e-01, -6.6118e-01,  7.0324e-02, -2.4696e-01,\n",
            "          2.6033e-01,  1.2379e-02,  5.5188e-01, -9.6472e-01, -2.1175e-01,\n",
            "         -9.5687e-02,  2.2072e-01,  2.5795e-02,  2.5246e-01,  7.6876e-01,\n",
            "          1.7454e-01, -5.3680e-01, -5.2671e-01,  3.7143e-02,  3.6676e-01,\n",
            "          7.2009e-01, -1.8866e-01,  1.2041e-02, -1.6240e-02, -1.2346e-01,\n",
            "         -9.4463e-01, -2.0757e-01, -3.0260e-01, -9.9823e-01,  5.8759e-01,\n",
            "         -1.0000e+00, -1.1292e-01, -5.9061e-01, -2.1318e-01,  8.8285e-01,\n",
            "          2.5759e-01,  1.0252e-01, -7.5484e-01,  1.2131e-01,  8.5764e-01,\n",
            "          7.7602e-01, -1.8561e-01,  4.2135e-02, -7.4542e-01,  1.6864e-01,\n",
            "          5.3778e-02,  1.1617e-01,  9.7810e-02,  7.4038e-01, -1.0685e-01,\n",
            "          1.0000e+00,  3.2789e-02, -4.5702e-01, -9.4049e-01,  1.3412e-01,\n",
            "         -1.1013e-01,  9.9998e-01, -7.7664e-01, -9.6900e-01,  2.6116e-01,\n",
            "         -4.9789e-01, -8.3380e-01,  2.3183e-01, -1.5132e-01, -5.7067e-01,\n",
            "         -4.3681e-01,  9.5803e-01,  5.8047e-01, -6.2078e-01,  4.3476e-01,\n",
            "         -2.3741e-01, -3.5270e-01, -3.5688e-02,  4.6110e-02,  9.9032e-01,\n",
            "          1.5869e-01,  8.7281e-01,  5.0530e-01,  1.8988e-02,  9.7528e-01,\n",
            "          2.2355e-01,  4.4153e-01,  4.4279e-02,  1.0000e+00,  2.4088e-01,\n",
            "         -9.2866e-01,  4.5149e-01, -9.8603e-01, -1.0453e-01, -9.5850e-01,\n",
            "          2.1405e-01,  7.3933e-02,  9.2658e-01, -2.0878e-01,  9.7117e-01,\n",
            "          8.2402e-02, -1.2471e-02, -1.5617e-01,  4.9960e-01,  3.7791e-01,\n",
            "         -9.3991e-01, -9.8843e-01, -9.9052e-01,  2.7608e-01, -2.8964e-01,\n",
            "         -5.1063e-04,  2.6147e-01,  3.5971e-02,  3.6402e-01,  4.1841e-01,\n",
            "         -1.0000e+00,  9.4863e-01,  2.9563e-01,  1.2836e-01,  9.7527e-01,\n",
            "          4.0925e-01,  3.3664e-01,  1.3525e-01, -9.9143e-01, -9.4920e-01,\n",
            "         -2.1290e-01, -1.8339e-01,  6.7256e-01,  6.0012e-01,  8.9723e-01,\n",
            "          3.2706e-01, -4.2008e-01, -1.8929e-01,  4.1730e-01, -4.6251e-01,\n",
            "         -9.9563e-01,  3.7109e-01,  2.8267e-01, -9.0501e-01,  9.6615e-01,\n",
            "         -6.0722e-01, -1.5370e-01,  6.3967e-01, -2.7028e-01,  8.7812e-01,\n",
            "          7.1810e-01,  2.1226e-01,  7.8555e-02,  5.0331e-01,  9.2063e-01,\n",
            "          9.2359e-01,  9.9276e-01,  5.7729e-02,  7.0656e-01,  1.4062e-01,\n",
            "          4.4387e-01,  8.0650e-01, -9.4631e-01,  6.9913e-02,  1.9651e-01,\n",
            "         -1.0941e-01,  1.9133e-01, -1.8200e-01, -9.3462e-01,  7.5673e-01,\n",
            "         -2.1779e-01,  4.1140e-01, -3.6436e-01,  2.1722e-01, -4.1534e-01,\n",
            "         -8.8859e-02, -6.3409e-01, -4.0851e-01,  7.0588e-01,  1.4006e-01,\n",
            "          9.1814e-01,  4.1889e-01,  5.7641e-02, -6.2939e-01, -5.0467e-02,\n",
            "          2.1591e-01, -9.2615e-01,  8.5117e-01,  1.8253e-02,  5.8238e-01,\n",
            "         -8.2124e-02, -9.4859e-02,  8.4325e-01, -3.1534e-01, -2.7121e-01,\n",
            "         -2.2465e-01, -6.9612e-01,  8.5127e-01, -4.7936e-01, -4.9178e-01,\n",
            "         -4.4064e-01,  6.5928e-01,  2.7886e-01,  9.9668e-01,  2.6245e-03,\n",
            "         -8.5388e-02, -2.6166e-01, -2.6522e-01,  3.6287e-01, -2.9788e-01,\n",
            "         -1.0000e+00,  2.0551e-01,  1.8404e-01,  1.9862e-01, -1.4529e-01,\n",
            "          6.4794e-02, -1.4123e-01, -9.7545e-01, -1.9969e-01,  3.2363e-01,\n",
            "         -1.3295e-01, -4.1897e-01, -3.2073e-01,  6.2045e-01,  2.0790e-01,\n",
            "          6.8996e-01,  8.6910e-01, -4.1384e-01,  7.2036e-01,  6.3852e-01,\n",
            "          5.9383e-02, -6.4438e-01,  9.1392e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
            "Retrieved Documents: ['Since it was built and opened to the public in 1889, the Eiffel Tower instantly gained an international fame, as it was then the tallest building in the world. Its peculiar iron silhouette instantly traveled across the world in the newspapers.', \"The Louvre is the world's largest art museum and a historic monument in Paris, France.\", 'The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor.', 'The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor.', 'The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor.']\n",
            "The Eiffel Tower was officially opened to the public in 1889. When it was first opened in 1889, the Eiffel Tower instantly gained an international fame.\n"
          ]
        }
      ]
    }
  ]
}